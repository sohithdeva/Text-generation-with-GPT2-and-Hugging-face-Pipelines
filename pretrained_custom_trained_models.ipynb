{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "pretrained/custom trained models.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElYAoI0IxTU8"
      },
      "source": [
        "# Installation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__XEGis7xF3F",
        "outputId": "70624ab9-5264-4a13-ba30-de84ed8c9cd5"
      },
      "source": [
        "!pip install -q git+https://github.com/huggingface/transformers.git\n",
        "! pip install tensorflow==1.14\n",
        "!pip install -q gpt-2-simple"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 901kB 14.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.3MB 36.8MB/s \n",
            "\u001b[?25h  Building wheel for transformers (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting tensorflow==1.14\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f4/28/96efba1a516cdacc2e2d6d081f699c001d414cc8ca3250e6d59ae657eb2b/tensorflow-1.14.0-cp37-cp37m-manylinux1_x86_64.whl (109.3MB)\n",
            "\u001b[K     |████████████████████████████████| 109.3MB 53kB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (3.12.4)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (1.1.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (1.15.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (0.36.2)\n",
            "Collecting tensorboard<1.15.0,>=1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/2d/2ed263449a078cd9c8a9ba50ebd50123adf1f8cfbea1492f9084169b89d9/tensorboard-1.14.0-py3-none-any.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 33.4MB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488kB)\n",
            "\u001b[K     |████████████████████████████████| 491kB 33.7MB/s \n",
            "\u001b[?25hCollecting keras-applications>=1.0.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (1.1.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (1.34.1)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (0.2.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (0.12.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (1.12.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (1.19.5)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (0.8.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.6.1->tensorflow==1.14) (56.1.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.3.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (1.0.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14) (3.1.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (4.0.1)\n",
            "Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.6->tensorflow==1.14) (1.5.2)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.4.1)\n",
            "\u001b[31mERROR: kapre 0.3.5 has requirement tensorflow>=2.0.0, but you'll have tensorflow 1.14.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorboard, tensorflow-estimator, keras-applications, tensorflow\n",
            "  Found existing installation: tensorboard 2.5.0\n",
            "    Uninstalling tensorboard-2.5.0:\n",
            "      Successfully uninstalled tensorboard-2.5.0\n",
            "  Found existing installation: tensorflow-estimator 2.5.0\n",
            "    Uninstalling tensorflow-estimator-2.5.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.5.0\n",
            "  Found existing installation: tensorflow 2.5.0\n",
            "    Uninstalling tensorflow-2.5.0:\n",
            "      Successfully uninstalled tensorflow-2.5.0\n",
            "Successfully installed keras-applications-1.0.8 tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0\n",
            "  Building wheel for gpt-2-simple (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gaeeQ5YQyfJm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a81ae73-202e-4f16-cd6e-9a910d64f85d"
      },
      "source": [
        "# Required libraries\n",
        "from transformers import pipeline\n",
        "from transformers import GPT2LMHeadModel,  GPT2Tokenizer, GPT2Config, GPT2LMHeadModel\n",
        "import torch\n",
        "\n",
        "# pipeline init\n",
        "text_generation = pipeline('text-generation')\n",
        "\n",
        "# instantiate the second model\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2') #gpt2-medium\n",
        "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
        "\n",
        "\n",
        "%tensorflow_version 1.x\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "import gpt_2_simple as gpt2\n",
        "from datetime import datetime\n",
        "from google.colab import files\n",
        "from google.colab import drive\n",
        "import os \n",
        "import requests\n",
        "# drive.mount('/content/drive')\n",
        "# %cd /content/drive/MyDrive/gpt2\n",
        "# gpt_model = gpt2.start_tf_sess()\n",
        "# gpt2.load_gpt2(gpt_model, run_name='run1')\n",
        "\n",
        "\n",
        "# function for pretty printing\n",
        "import textwrap\n",
        "\n",
        "wrapper = textwrap.TextWrapper(width=80,\n",
        "    initial_indent=\" \" * 4,\n",
        "    subsequent_indent=\" \" * 4,\n",
        "    break_long_words=False,\n",
        "    break_on_hyphens=False)\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/gpt2\n",
            "Loading checkpoint checkpoint/run1/model-100\n",
            "INFO:tensorflow:Restoring parameters from checkpoint/run1/model-100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OboBPs_pxmev"
      },
      "source": [
        "# Demo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEx7b9UZxoQP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "8695ed29-7fca-40d0-df11-cbe3b2f73fb4"
      },
      "source": [
        "#@title Enter the text and select model for text generation\n",
        "text = \" 'The total daily dose should not exceed 2.4g. Dosage should be reduced in patients with impaired renal function(see Special warnings and precautions for us Adults: For patients with duodenal or benign gastric ulceration, a single daily dose of 800mg at bedtime is recommended Otherwise the usual dosage is 400mg twice a day with breakfast and at bedtime. Other effective regimens are 200mg three times a day with meals and 400mg at bedtime (1.0g/day) and, if inadequate, 400mg four times a day (1.6g/day) also with meals and at bedtime. Symptomatic relief is usually rapid'\" #@param {type:\"string\"}\n",
        "select_model = \"Pretrained Pipeline\" #@param [\"Pretrained Pipeline\", \"Pretrained-GPT2(top_p=0.92, top_k=0)\",'Pretrained-GPT2(top_p=0.95, top_k=50)','Pretrained-GPT2(Basic- top_k=0)','Pretrained-GPT2(top_k=0,temperature=0.7)']\n",
        "\n",
        "#,\"Custom-GPT2\"\n",
        "if select_model == 'Pretrained Pipeline':\n",
        "  generated_text= text_generation(text, max_length=600, do_sample=True)[0]['generated_text']\n",
        "\n",
        "elif select_model == 'Pretrained-GPT2(top_p=0.92, top_k=0)':\n",
        "  ids = tokenizer.encode(text)\n",
        "  t = torch.LongTensor(ids)[None]\n",
        "  preds = model.generate(t, do_sample=True, max_length=600, top_p=0.92, top_k=0)\n",
        "  generated_text = tokenizer.decode(preds[0].numpy(), skip_special_tokens=True)\n",
        "\n",
        "elif select_model == 'Pretrained-GPT2(top_p=0.95, top_k=50)':\n",
        "  ids = tokenizer.encode(text)\n",
        "  t = torch.LongTensor(ids)[None]\n",
        "  preds = model.generate(t, do_sample=True, max_length=600, top_p=0.95, top_k=50)\n",
        "  generated_text = tokenizer.decode(preds[0].numpy(), skip_special_tokens=True)\n",
        "    \n",
        "elif select_model == 'Pretrained-GPT2(Basic- top_k=0)':\n",
        "  ids = tokenizer.encode(text)\n",
        "  t = torch.LongTensor(ids)[None]\n",
        "  preds = model.generate(t, do_sample=True, max_length=600, top_k=0)\n",
        "  generated_text = tokenizer.decode(preds[0].numpy(), skip_special_tokens=True)\n",
        "\n",
        "elif select_model == 'Pretrained-GPT2(top_k=0,temperature=0.7)':\n",
        "  ids = tokenizer.encode(text)\n",
        "  t = torch.LongTensor(ids)[None]\n",
        "  preds = model.generate(t,do_sample=True, max_length=600, top_k=0, temperature=0.7)\n",
        "  generated_text = tokenizer.decode(preds[0].numpy(), skip_special_tokens=True)\n",
        "\n",
        "# else:  \n",
        "#   output = gpt2.generate(gpt_model,\n",
        "#               length=600,\n",
        "#               temperature=0.7,\n",
        "#               prefix= text,\n",
        "#               nsamples=2,\n",
        "#               batch_size=2)\n",
        "#   generated_text = output\n",
        "\n",
        "if select_model == 'Custom-GPT2':\n",
        "  print('')\n",
        "else:\n",
        "  print(wrapper.fill(generated_text))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "     'The total daily dose should not exceed 2.4g. Dosage should be reduced in\n",
            "    patients with impaired renal function(see Special warnings and precautions\n",
            "    for us Adults: For patients with duodenal or benign gastric ulceration, a\n",
            "    single daily dose of 800mg at bedtime is recommended Otherwise the usual\n",
            "    dosage is 400mg twice a day with breakfast and at bedtime. Other effective\n",
            "    regimens are 200mg three times a day with meals and 400mg at bedtime\n",
            "    (1.0g/day) and, if inadequate, 400mg four times a day (1.6g/day) also with\n",
            "    meals and at bedtime. Symptomatic relief is usually rapid' in response to\n",
            "    regular administration of a mixture of vitamins, mineral, protein,\n",
            "    magnesium, magnesium c, and minerals, for as long as necessary. In some\n",
            "    cases the combined dose of vitamins, minerals (including, for example,\n",
            "    vitamin C), vitamins B6 and C 2 may be sufficient. Antioxidants are\n",
            "    essential in the prevention of disease in those patients who are deficient\n",
            "    in vitamins A, D, E, G, H, K, and M.  How does the combined serum albumin\n",
            "    and albuminII content of a given supplement affect myotisuria?  A combined\n",
            "    albumin and albuminII content of a given supplement may adversely affect\n",
            "    myotisuria. The albumin + albuminII content of a supplement may enhance the\n",
            "    incidence of myotisuria but also cause an increased risk of developing renal\n",
            "    or pulmonary disease from it.  How much is the combined content of each\n",
            "    vitamin and mineral in a supplement?  A small amount of vitamin A, 6, and 10\n",
            "    is found in each dose of vitamin C. An additional additional quantity,\n",
            "    1,2,4,6-dihydroxyfolate which is found in most human oral and breast milk,\n",
            "    is synthesized into vitamin C which is converted to D.  I have severe\n",
            "    myotisuria. Where is it done?  An intravenous urine test is the most\n",
            "    effective and very rapid test of myotisuria. Other tests may be administered\n",
            "    in conjunction with the IV drip (see Section 3, \"Clinical manifestations,\n",
            "    safety, effectiveness.\"). In some patients with myotisuria an IV drip is\n",
            "    needed in some cases to prevent further bleeding of the kidneys  The total\n",
            "    daily dose of vitamins 2-6 or 10 might be reduced in patients with this\n",
            "    problem using a combination of regular and low-dose IV drip combined with\n",
            "    intravenous blood, given only with intravenous blood. In some cases it might\n",
            "    improve. The combination of an IV or intravenous blood could result in less\n",
            "    bleeding of the intestine. Dosing of a combination of oral vitamin E and\n",
            "    vitamin D may be given in conjunction with IV drip combined with small doses\n",
            "    of vitamin E, vitamin D, and vitamin D plus B Vitamins 2-6 or 10. In those\n",
            "    patients with myotis\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}